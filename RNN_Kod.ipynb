{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5lHcMsHbNc8"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kelimeleri sınıflandırmak için temel bir karakter düzeyinde RNN oluşturup eğiteceğiz. Karakter düzeyinde bir RNN kelimeleri bir dizi karakter olarak okur - her adımda bir tahmin ve \"gizli durum\" çıktısı verir ve önceki gizli durumunu her bir sonraki adıma besler. Son tahmini çıktı olarak alırız, yani kelimenin hangi sınıfa ait olduğunu.\n",
        "\n",
        "Özellikle, 18 köken dilinden birkaç bin soyadı üzerinde eğitim vereceğiz ve bir ismin hangi dilden olduğunu yazımına göre tahmin edeceğiz:\n",
        "\n",
        "::"
      ],
      "metadata": {
        "id": "7VPA6OwkbpJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ python predict.py Hinton\n",
        "(-0.47) Scottish\n",
        "(-1.52) English\n",
        "(-3.57) Irish\n",
        "\n",
        "$ python predict.py Schmidhuber\n",
        "(-0.19) German\n",
        "(-2.48) Czech\n",
        "(-2.68) Dutch"
      ],
      "metadata": {
        "id": "c5NBS0xQcNNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verilerin Hazırlanması**"
      ],
      "metadata": {
        "id": "EX_Iz5prcaoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ".. Not:: Verileri buradan indirin <https://download.pytorch.org/tutorial/data.zip>_ ve geçerli dizine çıkarın.\n",
        "\n",
        "data/names dizininde \"[Language].txt\" adlı 18 metin dosyası bulunur. Her dosya, çoğunlukla romanize edilmiş (ancak yine de Unicode'dan ASCII'ye dönüştürmemiz gerekiyor) satır başına bir ad olmak üzere bir sürü ad içerir.\n",
        "\n",
        "Dil başına ad listelerinden oluşan bir sözlük elde edeceğiz, {language: [names ...]}. Genel değişkenler \"category\" ve \"line\" (bizim durumumuzda dil ve ad için) daha sonraki genişletilebilirlik için kullanılır."
      ],
      "metadata": {
        "id": "XvxP44zQcq-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Belirtilen bir dosya yolundaki tüm dosyaları bulan bir fonksiyon\n",
        "def findFiles(path): return glob.glob(path)\n",
        "\n",
        "# 'data/names/' klasöründeki tüm .txt dosyalarını bul ve listele\n",
        "print(findFiles('data/names/*.txt'))\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "# ASCII harfler ve bazı özel karakterler; isim verisi temizliği için kullanılacak\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "\n",
        "# Unicode karakterleri ASCII'ye dönüştüren fonksiyon\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "# Örnek bir isimde Unicode'dan ASCII'ye dönüşümün çıktısını gösterir\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Her bir kategoriye (ülkeye) ait isimlerin tutulacağı sözlük\n",
        "category_lines = {}\n",
        "# Tüm kategorilerin (ülkelerin) tutulacağı liste\n",
        "all_categories = []\n",
        "\n",
        "\n",
        "# Belirtilen dosyadan satırları okuyan fonksiyon\n",
        "def readLines(filename):\n",
        "    # Dosyadaki her satırı okuyup Unicode'dan ASCII'ye dönüştürür\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "# 'data/names/' klasöründeki her dosya için işlemler\n",
        "for filename in findFiles('data/names/*.txt'):\n",
        "    # Dosya adından kategori adını çıkar (örneğin, İngilizce için 'English')\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)  # Kategori listesini güncelle\n",
        "    lines = readLines(filename)      # Dosyadaki isimleri oku\n",
        "    category_lines[category] = lines  # Kategoriye ait isimleri sözlüğe ekle\n",
        "\n",
        "# Kategori (ülke) sayısını belirle\n",
        "n_categories = len(all_categories)"
      ],
      "metadata": {
        "id": "0lSnZ8kdc8ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi category_lines'ımız var, her kategoriyi (dil) bir satır listesine (isimler) eşleyen bir sözlük. Ayrıca all_categories'i (sadece bir dil listesi) ve n_categories'i daha sonra başvurmak üzere takip ettik."
      ],
      "metadata": {
        "id": "IwmZrrp3dKdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Italian' anahtarı altında bulunan ilk 5 ismi yazdır\n",
        "print(category_lines['Italian'][:5])"
      ],
      "metadata": {
        "id": "daifTlC1dTFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**İsimleri Tensörlere Dönüştürmek**"
      ],
      "metadata": {
        "id": "gk-TOGUUdUnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Artık tüm isimleri düzenlediğimize göre, bunları herhangi bir şekilde kullanmak için Tensörlere dönüştürmemiz gerekiyor.\n",
        "\n",
        "Tek bir harfi temsil etmek için, <1 x n_letters> boyutunda bir \"one-hot vektör\" kullanırız. One-hot vektör, geçerli harfin indeksindeki 1 hariç 0'larla doldurulur, örn. \"b\" = <0 1 0 0 0 ...>.\n",
        "\n",
        "Bir kelime oluşturmak için bunlardan bir demetini <line_length x 1 x n_letters> boyutunda bir 2B matrise birleştiririz.\n",
        "\n",
        "Bu ekstra 1 boyut, PyTorch'un her şeyin gruplar halinde olduğunu varsaymasından kaynaklanır - burada sadece 1'lik bir grup boyutu kullanıyoruz."
      ],
      "metadata": {
        "id": "_0sHURkadiug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# all_letters dizisinde belirtilen bir harfin indeksini bulan fonksiyon, örneğin \"a\" = 0\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "# Bir harfi <1 x n_letters> boyutunda bir tensöre çevirme fonksiyonu (örnek için)\n",
        "# Bu tensör bir \"one-hot\" vektörüdür, sadece belirli bir harfin konumunda 1 olur\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)  # <1 x n_letters> boyutunda sıfırlarla dolu bir tensör oluşturur\n",
        "    tensor[0][letterToIndex(letter)] = 1  # Harfin indeksine göre tensörde 1 olarak işaretler\n",
        "    return tensor\n",
        "\n",
        "# Bir metni <line_length x 1 x n_letters> boyutunda tensöre çevirme fonksiyonu\n",
        "# Bu tensör, harfleri \"one-hot\" vektörleri olarak temsil eden bir dizi içerir\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)  # Her harf için sıfırlardan oluşan bir tensör oluşturur\n",
        "    for li, letter in enumerate(line):  # Metindeki her harf için\n",
        "        tensor[li][0][letterToIndex(letter)] = 1  # Harfin indeksine göre tensörde 1 olarak işaretler\n",
        "    return tensor\n",
        "\n",
        "# 'J' harfini \"one-hot\" tensör olarak yazdır\n",
        "print(letterToTensor('J'))\n",
        "\n",
        "# 'Jones' kelimesini tensör boyutunda yazdır\n",
        "print(lineToTensor('Jones').size())"
      ],
      "metadata": {
        "id": "FNHS2d97d2fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ağ Oluşturma**"
      ],
      "metadata": {
        "id": "SKJTSpBKd8oj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autograd'dan önce, Torch'ta yinelemeli bir sinir ağı oluşturmak, bir katmanın parametrelerini birkaç zaman adımı boyunca klonlamayı içeriyordu. Katmanlar, artık tamamen grafiğin kendisi tarafından işlenen gizli durum ve eğimleri tutuyordu. Bu, bir RNN'yi çok \"saf\" bir şekilde, düzenli ileri beslemeli katmanlar olarak uygulayabileceğiniz anlamına gelir.\n",
        "\n",
        "Bu RNN modülü (çoğunlukla Torch kullanıcıları için PyTorch öğreticisinden kopyalanmıştır <http://pytorch.org/tutorials/beginner/former_torchies/ nn_tutorial.html#example-2-recurrent-net>__) yalnızca bir girdi ve gizli durum üzerinde çalışan 2 doğrusal katmandır ve çıktıdan sonra bir LogSoftmax katmanı vardır."
      ],
      "metadata": {
        "id": "6kVpZaTQeIqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# RNN sınıfını tanımlıyoruz, nn.Module sınıfını miras alıyor\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()  # nn.Module'ın özelliklerini RNN'e aktarır\n",
        "\n",
        "        self.hidden_size = hidden_size  # Gizli katmanın boyutu\n",
        "\n",
        "        # Giriş ve gizli durumun birleşiminden gizli duruma geçiş katmanı\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "        # Giriş ve gizli durumun birleşiminden çıkışa geçiş katmanı\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "\n",
        "        # Çıkış katmanı için LogSoftmax aktivasyon fonksiyonu\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    # İleri yayılım fonksiyonu, RNN'in giriş ve gizli durumu işleyerek çıktıyı üretmesini sağlar\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)  # Giriş ve gizli durumu birleştiriyoruz\n",
        "        hidden = self.i2h(combined)               # Yeni gizli durumu hesaplıyoruz\n",
        "        output = self.i2o(combined)               # Çıkış hesaplanıyor\n",
        "        output = self.softmax(output)             # LogSoftmax ile normalize ediliyor\n",
        "        return output, hidden                     # Çıktı ve yeni gizli durum döndürülüyor\n",
        "\n",
        "    # Başlangıç gizli durumu oluşturma fonksiyonu (başlangıçta tüm değerler 0)\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "# Gizli katman boyutu\n",
        "n_hidden = 128\n",
        "\n",
        "# RNN modelini başlatıyoruz, giriş boyutu n_letters, çıkış boyutu n_categories\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)"
      ],
      "metadata": {
        "id": "hRZvGZZtei2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu ağın bir adımını çalıştırmak için bir girdi (bizim durumumuzda, geçerli harf için Tensör) ve bir önceki gizli durumu (ilk başta sıfırlar olarak başlattığımız) geçirmemiz gerekir. Çıktıyı (her dilin olasılığı) ve bir sonraki gizli durumu (bir sonraki adım için sakladığımız) geri alacağız."
      ],
      "metadata": {
        "id": "JnIWafGdej-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'A' harfi için bir \"one-hot\" tensör oluşturuyoruz\n",
        "input = letterToTensor('A')\n",
        "\n",
        "# Gizli durumun başlangıç değeri olarak sıfırlardan oluşan bir tensör oluşturuyoruz\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "# RNN modeline 'A' harfi ve başlangıç gizli durumunu vererek çıktıyı ve bir sonraki gizli durumu elde ediyoruz\n",
        "output, next_hidden = rnn(input, hidden)\n"
      ],
      "metadata": {
        "id": "CzcOb5yXeqZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verimlilik uğruna her adım için yeni bir Tensör oluşturmak istemiyoruz, bu yüzden letterToTensor yerine lineToTensor kullanacağız ve dilimler kullanacağız. Bu, Tensörlerin toplu olarak önceden hesaplanmasıyla daha da iyileştirilebilir."
      ],
      "metadata": {
        "id": "No1AO8oBewaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Albert' ismini temsil eden bir tensör oluşturuyoruz.\n",
        "# Bu tensör, her harfi \"one-hot\" olarak temsil eden bir dizi tensörden oluşur.\n",
        "input = lineToTensor('Albert')\n",
        "\n",
        "# Gizli durumun başlangıç değeri olarak sıfırlardan oluşan bir tensör oluşturuyoruz\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "# İlk harfi (input[0]) ve gizli durumu RNN modeline vererek çıktıyı ve yeni gizli durumu alıyoruz\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "\n",
        "# Çıktıyı ekrana yazdırıyoruz; bu çıktı, modelin 'A' harfi ve başlangıç gizli durumu ile oluşturduğu tahmini temsil eder\n",
        "print(output)"
      ],
      "metadata": {
        "id": "raB6LLVGe-fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gördüğünüz gibi çıktı, her öğenin o kategorinin olasılığını gösterdiği <1 x n_categories> Tensörüdür (daha yüksek olması daha olasıdır)."
      ],
      "metadata": {
        "id": "S2TkmSM8e_YU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eğitim**"
      ],
      "metadata": {
        "id": "qrAZilNqfLmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eğitime Hazırlık**"
      ],
      "metadata": {
        "id": "HKMdH5JJfRne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eğitime başlamadan önce birkaç yardımcı fonksiyon yapmalıyız. Birincisi, her kategorinin bir olasılığı olduğunu bildiğimiz ağın çıktısını yorumlamaktır. En büyük değerin dizinini elde etmek için Tensor.topk'u kullanabiliriz:"
      ],
      "metadata": {
        "id": "E9tkb097faL4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM2_Gmf3V6Xy"
      },
      "outputs": [],
      "source": [
        "# Modelin çıktısından kategori tahminini belirleyen fonksiyon\n",
        "def categoryFromOutput(output):\n",
        "    # En yüksek değeri ve onun indeksini buluyoruz (bu kategori tahminidir)\n",
        "    top_n, top_i = output.topk(1)  # En yüksek olasılık değerine sahip olanı seçiyoruz\n",
        "    category_i = top_i[0].item()   # İndeksi bir Python tamsayısına çeviriyoruz\n",
        "    return all_categories[category_i], category_i  # Kategori adını ve indeksini döndürüyoruz\n",
        "\n",
        "# Tahmin edilen kategori ve indeksini ekrana yazdırıyoruz\n",
        "print(categoryFromOutput(output))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ayrıca bir eğitim örneğini (bir isim ve dili) elde etmenin hızlı bir yolunu da isteyeceğiz:"
      ],
      "metadata": {
        "id": "UhZ1c0RugANb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Listeden rastgele bir öğe seçen fonksiyon\n",
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "# Rastgele bir eğitim örneği oluşturan fonksiyon\n",
        "def randomTrainingExample():\n",
        "    # Kategoriler arasından rastgele bir kategori seçiyoruz\n",
        "    category = randomChoice(all_categories)\n",
        "\n",
        "    # Seçilen kategoriye ait isimler arasından rastgele bir isim seçiyoruz\n",
        "    line = randomChoice(category_lines[category])\n",
        "\n",
        "    # Kategori için indeks tensörünü oluşturuyoruz (kategori numarasını uzunluk türünde tensor yapıyoruz)\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "\n",
        "    # Seçilen ismi (line) tensöre çeviriyoruz\n",
        "    line_tensor = lineToTensor(line)\n",
        "\n",
        "    # Kategori adı, isim, kategori tensörü ve isim tensörünü döndürüyoruz\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "# 10 adet rastgele eğitim örneği oluşturup yazdırıyoruz\n",
        "for i in range(10):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    print('category =', category, '/ line =', line)"
      ],
      "metadata": {
        "id": "aM6kAOa8gFrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ağın Eğitimi**"
      ],
      "metadata": {
        "id": "pbpZRt6IgP5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi bu ağı eğitmek için gereken tek şey ona bir sürü örnek göstermek, tahminlerde bulunmasını sağlamak ve yanlışsa bunu söylemek.\n",
        "\n",
        "Kayıp fonksiyonu için nn.NLLLoss uygundur, çünkü RNN'nin son katmanı nn.LogSoftmax'tır."
      ],
      "metadata": {
        "id": "qf7IZCnTgTD0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU7RVfr_V6Xz"
      },
      "outputs": [],
      "source": [
        "# Negatif Log-Likelihood (NLL) kayıp fonksiyonunu tanımlıyoruz\n",
        "criterion = nn.NLLLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Her eğitim döngüsü şunları yapacaktır:\n",
        "-Giriş ve hedef tensörleri oluştur\n",
        "-Sıfırlanmış bir başlangıç ​​gizli durumu oluştur\n",
        "-Her harfi oku ve\n",
        "-Gizli durumu bir sonraki harf için sakla\n",
        "-Son çıktıyı hedefle karşılaştır\n",
        "-Geri yayılım\n",
        "-Çıktıyı ve kaybı döndür"
      ],
      "metadata": {
        "id": "qna73BQmgkcg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn9x2CvLV6Xz"
      },
      "outputs": [],
      "source": [
        "# Öğrenme oranını tanımlıyoruz; bu değer çok yüksek olursa model kararsızlaşabilir,\n",
        "# çok düşük olursa model öğrenim sürecini etkili bir şekilde gerçekleştiremeyebilir\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Modelin eğitimini gerçekleştiren fonksiyon\n",
        "def train(category_tensor, line_tensor):\n",
        "    # RNN için başlangıç gizli durumunu başlatıyoruz\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    # RNN modelinin gradyanlarını sıfırlıyoruz\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    # Girdi tensöründeki her harf için RNN modelini çalıştırıyoruz\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    # Çıktıyı ve kategori tensörünü kullanarak kaybı hesaplıyoruz\n",
        "    loss = criterion(output, category_tensor)\n",
        "\n",
        "    # Kayıp değerine göre gradyanları hesaplıyoruz\n",
        "    loss.backward()\n",
        "\n",
        "    # Öğrenme oranı ile çarpılan gradyanları, parametre değerlerine ekliyoruz\n",
        "    # Bu işlem, her parametrenin güncellenmesini sağlar\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(-learning_rate, p.grad.data)\n",
        "\n",
        "    # Son çıktıyı ve kayıp değerini döndürüyoruz\n",
        "    return output, loss.item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi bunu bir sürü örnekle çalıştırmamız gerekiyor. Train fonksiyonu hem çıktıyı hem de kaybı döndürdüğünden tahminlerini yazdırabilir ve ayrıca çizim için kaybı takip edebiliriz. 1000'lerce örnek olduğundan yalnızca her print_every örneğini yazdırırız ve kaybın ortalamasını alırız."
      ],
      "metadata": {
        "id": "3Oucs0-qg5dd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNPmcxhpV6Xz"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "# Toplam iterasyon sayısı\n",
        "n_iters = 100000\n",
        "# Her 5000 iterasyonda çıktı vermek için ayarlama\n",
        "print_every = 5000\n",
        "# Her 1000 iterasyonda kayıp değerini grafiğe eklemek için ayarlama\n",
        "plot_every = 1000\n",
        "\n",
        "# Kayıpları takip etmek için bir liste\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "# Geçen süreyi hesaplayan fonksiyon\n",
        "def timeSince(since):\n",
        "    now = time.time()  # Şu anki zamanı al\n",
        "    s = now - since    # Başlangıç zamanından bu yana geçen süreyi hesapla\n",
        "    m = math.floor(s / 60)  # Dakika cinsinden süreyi hesapla\n",
        "    s -= m * 60  # Saniye cinsinden süreyi hesapla\n",
        "    return '%dm %ds' % (m, s)  # Dakika ve saniyeyi döndür\n",
        "\n",
        "start = time.time()  # Eğitim süresini başlat\n",
        "\n",
        "# Eğitim döngüsü\n",
        "for iter in range(1, n_iters + 1):\n",
        "    # Rastgele bir eğitim örneği oluştur\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    # Modeli eğit ve kaybı hesapla\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss  # Geçerli kaybı güncelle\n",
        "\n",
        "    # Belirli bir iterasyonda çıktı ver\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)  # Modelin tahminini al\n",
        "        # Doğruluğu kontrol et\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        # İterasyon numarasını, kaybı ve tahmini yazdır\n",
        "        print('%d %d%% (%s) %.4f %s / %s %s' % (\n",
        "            iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # Geçerli kayıp ortalamasını kayıplar listesine ekle\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)  # Kayıp ortalamasını ekle\n",
        "        current_loss = 0  # Geçerli kaybı sıfırla\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sonuçların Çizilmesi**"
      ],
      "metadata": {
        "id": "BvowYoBEhDbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "all_losses'tan gelen tarihsel kaybın çizilmesi, ağ öğrenimini gösterir:"
      ],
      "metadata": {
        "id": "t5UBDht9hWa7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6PS47JEV6Xz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "# Yeni bir grafik oluştur\n",
        "plt.figure()\n",
        "# Kayıp değerlerini grafiğe çiz\n",
        "plt.plot(all_losses)\n",
        "\n",
        "# Eksenleri ayarlamak için ticker kullan\n",
        "plt.xlabel('Iterasyon (her 1000\\'de bir)')\n",
        "plt.ylabel('Kayıp (Loss)')\n",
        "plt.title('Eğitim Kaybı Grafiği')\n",
        "\n",
        "# Y ekseninde sayıları daha iyi göstermek için bir format belirle\n",
        "plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
        "\n",
        "# Grafiği göster\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sonuçların Değerlendirilmesi**"
      ],
      "metadata": {
        "id": "7be1iYNMhnbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ağın farklı kategorilerde ne kadar iyi performans gösterdiğini görmek için, her gerçek dil (satırlar) için ağın hangi dili tahmin ettiğini (sütunlar) belirten bir karışıklık matrisi oluşturacağız. Karışıklık matrisini hesaplamak için bir grup örnek, train() eksi geri yayılımla aynı olan assess() ile ağda çalıştırılır."
      ],
      "metadata": {
        "id": "bCplfgP-hpGf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAFEqPF2V6Xz"
      },
      "outputs": [],
      "source": [
        "# Doğru tahminleri takip etmek için bir karmaşa matrisini başlat\n",
        "confusion = torch.zeros(n_categories, n_categories)  # n_categories x n_categories boyutunda sıfırlardan oluşan bir matris\n",
        "n_confusion = 10000  # Değerlendirme için kullanılacak örnek sayısı\n",
        "\n",
        "# Bir satıra verilen çıktıyı döndürmek için fonksiyon\n",
        "def evaluate(line_tensor):\n",
        "    hidden = rnn.initHidden()  # RNN'in gizli durumunu başlat\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)  # Her harf için çıkışı hesapla\n",
        "\n",
        "    return output  # Son çıkışı döndür\n",
        "\n",
        "# Birçok örneği geçerek hangi tahminlerin doğru yapıldığını kaydet\n",
        "for i in range(n_confusion):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()  # Rastgele bir eğitim örneği al\n",
        "    output = evaluate(line_tensor)  # Örneği değerlendir\n",
        "    guess, guess_i = categoryFromOutput(output)  # Tahmin edilen kategoriyi al\n",
        "    category_i = all_categories.index(category)  # Gerçek kategorinin indeksini bul\n",
        "    confusion[category_i][guess_i] += 1  # Karmaşa matrisinde doğru tahmini güncelle\n",
        "\n",
        "# Her satırı kendi toplamına bölerek normalize et\n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()  # Satır toplamına böl\n",
        "\n",
        "# Grafik ayarları\n",
        "fig = plt.figure()  # Yeni bir figür oluştur\n",
        "ax = fig.add_subplot(111)  # 1x1'lik bir ızgarada ilk alt grafiği oluştur\n",
        "cax = ax.matshow(confusion.numpy())  # Karmaşa matrisini görselleştir\n",
        "fig.colorbar(cax)  # Renk çubuğunu ekle\n",
        "\n",
        "# Eksen ayarları\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)  # X eksenindeki etiketleri ayarla\n",
        "ax.set_yticklabels([''] + all_categories)  # Y eksenindeki etiketleri ayarla\n",
        "\n",
        "# Her tikte etiket zorla\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))  # X eksenindeki her bir tike bir etiket yerleştir\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))  # Y eksenindeki her bir tike bir etiket yerleştir\n",
        "\n",
        "# Grafiği göster\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ana eksenden hangi dilleri yanlış tahmin ettiğini gösteren parlak noktaları seçebilirsiniz, örneğin Korece için Çince ve İtalyanca için İspanyolca. Yunanca ile çok iyi, İngilizce ile ise çok kötü (belki de diğer dillerle örtüşmesinden dolayı)."
      ],
      "metadata": {
        "id": "SmeoaEY4h25f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kullanıcı Girişiyle Çalışma**"
      ],
      "metadata": {
        "id": "TtN90T7TiEnW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO_HkKmdV6Xz"
      },
      "outputs": [],
      "source": [
        "def predict(input_line, n_predictions=3):\n",
        "    # Kullanıcıdan alınan girdi satırını yazdır\n",
        "    print('\\n> %s' % input_line)\n",
        "    with torch.no_grad():  # Gradyan hesaplamasını kapat (eğitim aşaması değil)\n",
        "        output = evaluate(lineToTensor(input_line))  # Girdi satırını değerlendir\n",
        "\n",
        "        # En yüksek N kategoriyi al\n",
        "        topv, topi = output.topk(n_predictions, 1, True)  # En yüksek n_predictions değerini ve indekslerini al\n",
        "        predictions = []  # Tahminleri saklamak için bir liste oluştur\n",
        "\n",
        "        # Tahmin edilen kategorileri ve değerlerini yazdır\n",
        "        for i in range(n_predictions):\n",
        "            value = topv[0][i].item()  # Tahmin edilen değer\n",
        "            category_index = topi[0][i].item()  # Tahmin edilen kategorinin indeksi\n",
        "            print('(%.2f) %s' % (value, all_categories[category_index]))  # Değeri ve kategoriyi yazdır\n",
        "            predictions.append([value, all_categories[category_index]])  # Tahminleri listeye ekle\n",
        "\n",
        "# Örnek girdilerle tahminleri yap\n",
        "predict('Dovesky')  # 'Dovesky' ismi için tahmin yap\n",
        "predict('Jackson')  # 'Jackson' ismi için tahmin yap\n",
        "predict('Satoshi')  # 'Satoshi' ismi için tahmin yap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical PyTorch deposundaki betiklerin son sürümleri <https://github.com/spro/practical-pytorch/tree/master/char-rnn-classification>__ yukarıdaki kodu birkaç dosyaya böldü:\n",
        "\n",
        "-data.py (dosyaları yükler)\n",
        "-model.py (RNN'i tanımlar)\n",
        "-train.py (eğitimi çalıştırır)\n",
        "-predict.py (predict()'i komut satırı argümanlarıyla çalıştırır)\n",
        "-server.py (tahmini bottle.py ile JSON API olarak sunar)\n",
        "\n",
        "Ağı eğitmek ve kaydetmek için train.py'yi çalıştırın.\n",
        "\n",
        "Tahminleri görüntülemek için predict.py'yi bir adla çalıştırın:"
      ],
      "metadata": {
        "id": "wnmX5VTdiS_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n6LGKr2AiUdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ python predict.py Hazaki\n",
        "\n",
        "(-0.42) Japanese\n",
        "\n",
        "(-1.39) Polish\n",
        "\n",
        "(-3.51) Czech"
      ],
      "metadata": {
        "id": "Bxm3W4c9iulj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GAugoQwliv2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "server.py'ı çalıştırın ve tahminlerin JSON çıktısını almak için http://localhost:5533/Adınız adresine gidin."
      ],
      "metadata": {
        "id": "V0LUH-tRi7WC"
      }
    }
  ]
}